# Lab 3.4: Updating conda to include additional external dependencies for deep learning or mml

## What is conda?

Conda is an multi-platform, open-source package management system. Fundamentally it tries to solve replicability by creating a clearn environment in which our code and all its dependencies can be placed and run. It is primarily used for python, but can be used for multiple languages (including R). It is generally packaged and distributed through the Anaconda python distribution supported by Anaconda, Inc (a Microsoft partner).

In the context of Python, Conda is similar to `pip` and can be used to install and update Python packages, but Conda goes beyond that and also installs library dependencies outside of Python, such as C++ dependencies.

With Azure ML Workbench projects, we use Docker for managing system requirements and dependencies between compute environments (local, remote, Spark). Within Docker itself, we use Conda to manage Python dependencies for a given project.

CRITICAL NOTE: conda is not used (by default) for local script runs, which use the root environment instead. This can cause dependencies to break between compute environments. As a general rule, it is better to use Docker even when working locally.

1. We use the command line write `conda` commands. Open the Workbench and create a new project called `iris_classification`. Choose the **Classifying Iris** as your project template and your `Documents` folder as its directory. Open the project and go to **File > Open Command Prompt** to access the command line from within the project parent folder. Type `conda --version` to see the version of conda installed. Type `conda list` to see a listing of installed python packages. Some of these packages are installed using `pip` or `easy_install`, some are installed using `conda install`.
2. Open the `conda_dependencies.yml` file and examine the content. What package dependencies are specified here? Notice how some packages don't have versions associated with them. This is generally a bad practice, so we will fix that now by binding our project to a specific version of matplotlib. To edit `conda_dependencies.yml`, open your project in Code, then in line 15 change `matplotlib` with `matplotlib==2.0.2`. Then go to `iris_sklearn.py` and add a new line after line 101 and paste in `print("matplotlib version: {}", matplotlib.__version__)`, keeping the indentation. Save your changes.
3. Return to Workbench and verify that the changes you made are visible. Now run `iris_sklearn.py` using Docker as the compute environment. This will take a few minutes. After your run finishes, sumbit it a second time, but this time instead of clicking the run button we go to **File > Open Command Prompt** and submit the run programmatically by pasting the following command: `az ml experiment submit -c docker-python iris_sklearn.py`. The first time we submitted the code, it took a few minutes for it to finish running because Docker needs to create a new image, but the second time things will run much faster.
4. In the Workbench, go to the **Jobs** panel on the right and click on the green **Completed** button to see any results printed by the script. Can you find the `matplotlib` version number we asked the script to print? Does it match the version number in `conda_dependencies.yml`?
5. Conda creates an execution environment for our project and binds our Python scripts and their dependencies so that its execution environment can be isolated from that of other projects. My submitting the above command, we created a Docker image with our project and used Conda to handle our script and its dependencies by creating a new Conda environment for the project. To see this, return to the Command Prompt and type `python`, then in the python console type `import matplotlib; print(matplotlib.__version__)`. Compare your `matplotlib` version to the one we obtained in the last step.
6. In we created a Conda environment automatically in the last step is because in the `aml_config/docker-python.runconfig` file we point to `conda_dependencies.yml` and we set `PrepareEnvironment: true` in line 9. We can also manually create a conda environment, which is what we do when we're still in the process of writing and testing our Python scripts. To create an environment, we go to the Command Prompt and run `conda env create -f aml_config/conda_dependencies.yml`, which creates an environment called `project_environment` by default (we can rename it using the `-n` switch). Once an environment is created, it needs to be activated using `activate project_environment`. Run these two commands from the Command Prompt and type `python`, then in the python console type `import matplotlib; print(matplotlib.__version__)`. Compare your `matplotlib` version to the one we obtained in the last two step. Which one does it match?
7. To deactivate an environment simply type `deactivate`. Note that an environment is only active for the open Command Prompt session and will be deactivated if we close the session. We can also permanently remove this environment using `conda env remove -n project_environment`.

If working locally without the use of Conda environments, we would be using our local root Python installation, which means that all projects would rely on the same environment and where conflicting dependencies can cause collusion, and where missing system dependencies can cause headaches when going from development to staging or production. Therefore, if working locally it is still better to leverage Docker as we did above. However, Docker is not always available on Windows machines. On the DSVM for example, we need to use `D_v3` instances (and enable Hyper-V) in order be able to install and use Docker. When docker is not an option and we can only work locally, then we can (and definitely should) still use Conda.

8. From the Command Prompt, create a new Conda environment by pointing to `conda_dependencies.yml` and use `-n iris_env` to rename it from `project_environment` to `iris_env`. Go to the `aml_config/local.compute` file and point the Python location from the root Python directory to the Python directory specific to this environment. You can do so by replacing `pythonLocation: "python"` with `pythonLocation: "%USERPROFILE%/AppData/Local/amlworkbench/Python/envs/iris_env/python.exe"`. To make sure that this works, run `iris_sklearn.py` locally and inspect the results generated by the script (just as we did in step 3). Does the `matplotlib` package version match what we specified in `conda_dependencies.yml`?

## Conclusions

When developing your code

1. Absolutely use versions in `conda_dependencies.yml`.
2. Leverage Docker and Conda environments for every project. A docker-python environment manages system dependencies as well.
3. If your Windows machine does not have Docker and you are limited to working locally, you should still leverage Conda environments but be prepared to deal with additional system dependencies when moving to staging or production. The most common ones are compiler-related (such as C++ and Fortran). In Addition, there are currently AzureML dependencies issues with local Conda environments.
